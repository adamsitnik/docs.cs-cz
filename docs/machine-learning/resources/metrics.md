---
title: Metriky ML.NET
description: Principy, která se používají k vyhodnocení výkonu modelu ML.NET
ms.date: 04/29/2019
author: ''
ms.openlocfilehash: 802f0a8fd32c492c8d9f89933b183802cb178cb3
ms.sourcegitcommit: 7e129d879ddb42a8b4334eee35727afe3d437952
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 05/23/2019
ms.locfileid: "66053046"
---
# <a name="model-evaluation-metrics-in-mlnet"></a><span data-ttu-id="92889-103">Model metrik v ML.NET</span><span class="sxs-lookup"><span data-stu-id="92889-103">Model evaluation metrics in ML.NET</span></span>

## <a name="metrics-for-binary-classification"></a><span data-ttu-id="92889-104">Metriky pro binární klasifikaci</span><span class="sxs-lookup"><span data-stu-id="92889-104">Metrics for Binary Classification</span></span>

| <span data-ttu-id="92889-105">Metriky</span><span class="sxs-lookup"><span data-stu-id="92889-105">Metrics</span></span>   |      <span data-ttu-id="92889-106">Popis</span><span class="sxs-lookup"><span data-stu-id="92889-106">Description</span></span>      |  <span data-ttu-id="92889-107">Hledat</span><span class="sxs-lookup"><span data-stu-id="92889-107">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="92889-108">**Přesnost**</span><span class="sxs-lookup"><span data-stu-id="92889-108">**Accuracy**</span></span> |  <span data-ttu-id="92889-109">[Přesnost](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) je poměr správné předpovědi s testovací datové sady.</span><span class="sxs-lookup"><span data-stu-id="92889-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="92889-110">Je poměr počtu správné predikcí celkového počtu vstupních vzorků.</span><span class="sxs-lookup"><span data-stu-id="92889-110">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="92889-111">To funguje dobře pouze pokud jsou podobné počet vzorků, které patří ke každé třídě.</span><span class="sxs-lookup"><span data-stu-id="92889-111">It works well only if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="92889-112">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-112">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="92889-113">Přesně 1,00 označuje potíže, ale (běžně: popisek/cílového únikům over-pass-the těsně a testování s trénovací data).</span><span class="sxs-lookup"><span data-stu-id="92889-113">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="92889-114">Když jsou data testu nevyvážené uvozovky (kde většina instancí patří do jedné ze tříd), datové sady je velmi malý nebo skóre přístup 0,00 nebo 1,00, pak přesnost nezachytí skutečně efektivitu třídění a je potřeba zkontrolovat další metriky.</span><span class="sxs-lookup"><span data-stu-id="92889-114">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is very small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="92889-115">**AUC**</span><span class="sxs-lookup"><span data-stu-id="92889-115">**AUC**</span></span> |    <span data-ttu-id="92889-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) nebo *oblasti pod křivkou*: To je měření oblasti pod křivkou vytvořené cílit na konkrétní hodnotu true kladné míra vs. míru falešně pozitivních výsledků.</span><span class="sxs-lookup"><span data-stu-id="92889-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve*: This is measuring the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="92889-117">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-117">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="92889-118">By měla být větší než 0,50 modelu jako přijatelné; bezcenné. podstatné je model s AUC 0,50 nebo i rychleji.</span><span class="sxs-lookup"><span data-stu-id="92889-118">It should be greater than 0.50 for a model to be acceptable; a model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="92889-119">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="92889-119">**AUCPR**</span></span> | <span data-ttu-id="92889-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) nebo *oblasti pod křivkou křivky přesnosti a úplnosti*: Užitečné měření úspěchu předpovědí při třídy jsou velmi imbalanced (s výrazně nerovnoměrnou distribucí datové sady).</span><span class="sxs-lookup"><span data-stu-id="92889-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are very imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="92889-121">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="92889-122">Vysoké hodnocení blížící se 1,00 zobrazení, třídění je vrácení přesné výsledky (vysoká přesnost), stejně jako vrácení většinou všechny pozitivních výsledků (vysoká odvolání).</span><span class="sxs-lookup"><span data-stu-id="92889-122">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="92889-123">**F1 skóre**</span><span class="sxs-lookup"><span data-stu-id="92889-123">**F1-score**</span></span> | <span data-ttu-id="92889-124">[Skóre F1](https://en.wikipedia.org/wiki/F1_score) označované také jako *balanced skóre F nebo F míru*.</span><span class="sxs-lookup"><span data-stu-id="92889-124">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="92889-125">Je průměr přesnosti a odvolání.</span><span class="sxs-lookup"><span data-stu-id="92889-125">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="92889-126">F1 skóre je užitečné, když chcete hledají rovnováhu mezi přesnosti a odvolání.</span><span class="sxs-lookup"><span data-stu-id="92889-126">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="92889-127">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-127">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="92889-128">Skóre F1 dosáhne jeho nejlepší poměr na 1,00 a nejhorší skóre v 0,00.</span><span class="sxs-lookup"><span data-stu-id="92889-128">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="92889-129">Zjistíte, jak přesně je klasifikátoru.</span><span class="sxs-lookup"><span data-stu-id="92889-129">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="92889-130">Další podrobnosti o binární klasifikace metrik najdete v následujících článcích:</span><span class="sxs-lookup"><span data-stu-id="92889-130">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="92889-131">Přesnost, zaokrouhlení, odvolání nebo stisknutím F1?</span><span class="sxs-lookup"><span data-stu-id="92889-131">Accuracy, Precision, Recall or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="92889-132">Binární klasifikace metriky třídy</span><span class="sxs-lookup"><span data-stu-id="92889-132">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="92889-133">Vztah mezi přesnosti a úplnosti a křivky roc s více TŘÍDAMI</span><span class="sxs-lookup"><span data-stu-id="92889-133">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="metrics-for-multi-class-classification"></a><span data-ttu-id="92889-134">Metriky pro klasifikace víc tříd</span><span class="sxs-lookup"><span data-stu-id="92889-134">Metrics for Multi-class Classification</span></span>

| <span data-ttu-id="92889-135">Metriky</span><span class="sxs-lookup"><span data-stu-id="92889-135">Metrics</span></span>   |      <span data-ttu-id="92889-136">Popis</span><span class="sxs-lookup"><span data-stu-id="92889-136">Description</span></span>      |  <span data-ttu-id="92889-137">Hledat</span><span class="sxs-lookup"><span data-stu-id="92889-137">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="92889-138">**Micro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="92889-138">**Micro-Accuracy**</span></span> |  <span data-ttu-id="92889-139">[Průměr Micro přesnost](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agreguje vaše příspěvky všechny třídy pro výpočet průměrné metriku.</span><span class="sxs-lookup"><span data-stu-id="92889-139">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="92889-140">Jedná se o zlomek instance správně předpovědět.</span><span class="sxs-lookup"><span data-stu-id="92889-140">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="92889-141">Průměr micro nepřijímá členství ve třídě v úvahu.</span><span class="sxs-lookup"><span data-stu-id="92889-141">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="92889-142">V podstatě každá dvojice ukázkovou třídu přispívá stejně metriky přesnosti.</span><span class="sxs-lookup"><span data-stu-id="92889-142">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="92889-143">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-143">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="92889-144">V rámci úlohy klasifikace roc micro přesnost je vhodnější než přes – makro přesnost Pokud máte podezření, že může být třída imbalance (např.)</span><span class="sxs-lookup"><span data-stu-id="92889-144">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="92889-145">Možná budete muset mnoho dalších příkladů jedné třídy než jiné třídy).</span><span class="sxs-lookup"><span data-stu-id="92889-145">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="92889-146">**Macro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="92889-146">**Macro-Accuracy**</span></span> | <span data-ttu-id="92889-147">[Average – makro přesnost](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) je průměrná přesností na úrovni třídy.</span><span class="sxs-lookup"><span data-stu-id="92889-147">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="92889-148">Je vypočítán přesnost pro každou třídu a přesnost – makro je průměrem těchto přesností.</span><span class="sxs-lookup"><span data-stu-id="92889-148">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="92889-149">V podstatě každá třída přispívá stejně metriky přesnosti.</span><span class="sxs-lookup"><span data-stu-id="92889-149">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="92889-150">Třídy minority disponují stejnou váhu jako větší třídy.</span><span class="sxs-lookup"><span data-stu-id="92889-150">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="92889-151">Metrika – makro průměr poskytuje stejnou váhou pro každou třídu, bez ohledu na to, kolik instancí od, který obsahuje třídu datové sady.</span><span class="sxs-lookup"><span data-stu-id="92889-151">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="92889-152">**Blíže k 1,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-152">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="92889-153">Vypočítá metrika nezávisle pro každou třídu a potom vezme v průměru (tedy. považuje všechny třídy stejně)</span><span class="sxs-lookup"><span data-stu-id="92889-153">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="92889-154">**Log-loss**</span><span class="sxs-lookup"><span data-stu-id="92889-154">**Log-loss**</span></span>| <span data-ttu-id="92889-155">[Logaritmické ztrátu](http://wiki.fast.ai/index.php/Log_Loss) měří výkonnost model klasifikace, kde je hodnota pravděpodobnosti mezi 0,00 a 1,00 vstup předpovědi.</span><span class="sxs-lookup"><span data-stu-id="92889-155">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="92889-156">Ztráta protokolu zvyšuje podle pravděpodobnost předpovězené diverges od skutečné popisku.</span><span class="sxs-lookup"><span data-stu-id="92889-156">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="92889-157">**Blíže k 0,00, tím lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-157">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="92889-158">Ideální model by měla mít protokolu ztrátu 0,00.</span><span class="sxs-lookup"><span data-stu-id="92889-158">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="92889-159">Cílem naší modelů strojového učení je minimalizovat tuto hodnotu.</span><span class="sxs-lookup"><span data-stu-id="92889-159">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="92889-160">**Omezení protokolu ztráty**</span><span class="sxs-lookup"><span data-stu-id="92889-160">**Log-Loss Reduction**</span></span> | <span data-ttu-id="92889-161">[Snížení logaritmické ztrátu](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) může být interpretován jako výhod třídění přes náhodné předpovědi.</span><span class="sxs-lookup"><span data-stu-id="92889-161">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="92889-162">**V rozsahu od -inf a 1,00, kde 1,00 je ideální předpovědi a 0,00 označuje střední predikcí**.</span><span class="sxs-lookup"><span data-stu-id="92889-162">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="92889-163">Například pokud je hodnota 0.20 a novější, to může být interpretován tak "pravděpodobnost správného předpovědi je lepší než náhodných opakovaně uhodnout 20 %"</span><span class="sxs-lookup"><span data-stu-id="92889-163">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="92889-164">Micro přesnost je obecně lepší v souladu s obchodní potřeby predikce ML.</span><span class="sxs-lookup"><span data-stu-id="92889-164">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="92889-165">Pokud chcete vybrat jednu metriku pro výběr kvality úlohu klasifikace víc tříd, mělo by být obvykle micro přesnost.</span><span class="sxs-lookup"><span data-stu-id="92889-165">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="92889-166">Například pro úkol klasifikace lístku podpory: (mapuje příchozí lístky pro podporu týmů)</span><span class="sxs-lookup"><span data-stu-id="92889-166">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="92889-167">Přesnost Micro – jak často lístek příchozí získat zařazených do správný tým?</span><span class="sxs-lookup"><span data-stu-id="92889-167">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="92889-168">Přesnost – makro – průměrná týmu, jak často se lístek příchozí správnou pro jejich tým?</span><span class="sxs-lookup"><span data-stu-id="92889-168">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="92889-169">Malé týmy v tomto příkladu; overweights přesnost – makro malý tým, který získá jenom 10 lístky za rok se počítá tak, jak velký tým s 10 tisíc lístky za rok.</span><span class="sxs-lookup"><span data-stu-id="92889-169">Macro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="92889-170">Přesnost Micro v tomto případě koreluje lépe se obchodní potřeby, "kolik čas a peníze může společnost uložit tím, že automatizuje proces směrování lístku".</span><span class="sxs-lookup"><span data-stu-id="92889-170">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="92889-171">Další informace o klasifikaci roc metrik najdete v následujících článcích:</span><span class="sxs-lookup"><span data-stu-id="92889-171">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="92889-172">Micro – a – makro – průměr přesnost, odvolání a skóre F</span><span class="sxs-lookup"><span data-stu-id="92889-172">Micro- and Macro-average of Precision, Recall and F-Score</span></span>](http://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="92889-173">Klasifikace víc tříd s datovou sadou Imbalanced</span><span class="sxs-lookup"><span data-stu-id="92889-173">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="metrics-for-regression"></a><span data-ttu-id="92889-174">Metriky pro regresní</span><span class="sxs-lookup"><span data-stu-id="92889-174">Metrics for Regression</span></span>

| <span data-ttu-id="92889-175">Metriky</span><span class="sxs-lookup"><span data-stu-id="92889-175">Metrics</span></span>   |      <span data-ttu-id="92889-176">Popis</span><span class="sxs-lookup"><span data-stu-id="92889-176">Description</span></span>      |  <span data-ttu-id="92889-177">Hledat</span><span class="sxs-lookup"><span data-stu-id="92889-177">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="92889-178">**Spolehlivosti R**</span><span class="sxs-lookup"><span data-stu-id="92889-178">**R-Squared**</span></span> |  <span data-ttu-id="92889-179">[Plánovaná (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), nebo *koeficient spolehlivosti* představuje výkon prediktivní model jako hodnotu mezi -inf a 1,00.</span><span class="sxs-lookup"><span data-stu-id="92889-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="92889-180">1,00 znamená, že se skvěle hodí, a přizpůsobit můžou být arbitrarly nízký, proto skóre, které mohou být záporná.</span><span class="sxs-lookup"><span data-stu-id="92889-180">1.00 means there is a perfect fit, and the fit can be arbitrarly poor so the scores can be negative.</span></span> <span data-ttu-id="92889-181">Skóre 0,00 znamená, že model je opakovaně uhodnout očekávanou hodnotou pro popisek.</span><span class="sxs-lookup"><span data-stu-id="92889-181">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="92889-182">R2 měří jak blízko skutečné testovací datové hodnoty jsou předpovězeným hodnotám.</span><span class="sxs-lookup"><span data-stu-id="92889-182">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="92889-183">**Blíže k 1,00, lepší kvalitu**.</span><span class="sxs-lookup"><span data-stu-id="92889-183">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="92889-184">Ale někdy nízké hodnoty spolehlivosti (například 0,50) může být zcela normální nebo dostatečné pro váš scénář a vysoké spolehlivosti R hodnoty nejsou vždy dobré a dávejte pozor.</span><span class="sxs-lookup"><span data-stu-id="92889-184">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="92889-185">**Absolutní ztráty**</span><span class="sxs-lookup"><span data-stu-id="92889-185">**Absolute-loss**</span></span> |  <span data-ttu-id="92889-186">[Absolutní ztrátu](https://en.wikipedia.org/wiki/Mean_absolute_error) nebo *střední absolutní chyba (MAE)* měří jak blízko předpovědi se skutečné výsledky.</span><span class="sxs-lookup"><span data-stu-id="92889-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="92889-187">Je průměrem všechny chyby modelu, kde je chyba modelu absolutní vzdálenost mezi předpokládané popisek hodnotu a hodnotu správný popisek.</span><span class="sxs-lookup"><span data-stu-id="92889-187">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="92889-188">Tato chyba predikcí se počítá pro každý záznam testovací datové sady.</span><span class="sxs-lookup"><span data-stu-id="92889-188">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="92889-189">Nakonec se počítá střední hodnoty pro všechny nahrané absolutních chyb.</span><span class="sxs-lookup"><span data-stu-id="92889-189">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="92889-190">**Blíže k 0,00, lepší kvality.**</span><span class="sxs-lookup"><span data-stu-id="92889-190">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="92889-191">Všimněte si, že střední absolutní chyba používá stejné měřítko jako data měří (není normalizovány na konkrétní rozsah).</span><span class="sxs-lookup"><span data-stu-id="92889-191">Note that the mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="92889-192">Absolutní ztráty, Squared ztráty a ztráty RMS jde použít jenom k porovnání mezi modely pro stejné datové sadě nebo datovou sadu s distribuce hodnoty podobné popisek.</span><span class="sxs-lookup"><span data-stu-id="92889-192">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a smilar label value distribution.</span></span> |
| <span data-ttu-id="92889-193">**Spolehlivosti ztráty**</span><span class="sxs-lookup"><span data-stu-id="92889-193">**Squared-loss**</span></span> |  <span data-ttu-id="92889-194">[Squared ztrátu](https://en.wikipedia.org/wiki/Mean_squared_error) nebo *znamenat chyba spolehlivosti (MSE)*, označované také jako *znamenat spolehlivosti odchylka (program MSD)*, zjistíte, jak blízko řádku regrese do sady testů datových hodnot.</span><span class="sxs-lookup"><span data-stu-id="92889-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values.</span></span> <span data-ttu-id="92889-195">Dělá to tak, že trvá daleko od bodů na regresní přímky (Tyto vzdálenosti se chyby E) a jejich umocnění na druhou.</span><span class="sxs-lookup"><span data-stu-id="92889-195">It does this by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="92889-196">Umocňování poskytuje větší váhu k větší rozdíly.</span><span class="sxs-lookup"><span data-stu-id="92889-196">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="92889-197">Vždy je záporná, a **hodnoty blíže k 0,00 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-197">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="92889-198">V závislosti na vašich dat může být možné získat velmi malou hodnotu pro střední kvadratické chyby.</span><span class="sxs-lookup"><span data-stu-id="92889-198">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="92889-199">**RMS-loss**</span><span class="sxs-lookup"><span data-stu-id="92889-199">**RMS-loss**</span></span> |  <span data-ttu-id="92889-200">[RMS při ztrátě](https://en.wikipedia.org/wiki/Root-mean-square_deviation) nebo *kořenové znamenat spolehlivosti chyby (RMSE)* (také nazývané *kořenové směrodatná odchylka, RMSD*), měří rozdíl mezi hodnotami předpovídané pomocí modelu a hodnotami ve skutečnosti zjištěnými z prostředí, které je právě modelovat.</span><span class="sxs-lookup"><span data-stu-id="92889-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values actually observed from the environment that is being modeled.</span></span> <span data-ttu-id="92889-201">Ztráta RMS je odmocninu Squared ztráty a má stejné jednotky jako popisek, podobně jako absolutní ztrát v případě, že poskytuje větší váhu větší rozdíly.</span><span class="sxs-lookup"><span data-stu-id="92889-201">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the abolute-loss though giving more weight to larger diferences.</span></span> <span data-ttu-id="92889-202">Průměrná kvadratická chyba se běžně používá v klimatologie, Prognózování a regresní analýzy ověřit výsledky.</span><span class="sxs-lookup"><span data-stu-id="92889-202">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="92889-203">Vždy je záporná, a **hodnoty blíže k 0,00 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="92889-203">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="92889-204">RMSD je míra přesnost porovnání Prognózování chyby z různých modelů pro konkrétní datové sady a není mezi datovými sadami, protože je závislé na škálování.</span><span class="sxs-lookup"><span data-stu-id="92889-204">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="92889-205">Další podrobnosti týkající se metrik Regrese v následujících článcích:</span><span class="sxs-lookup"><span data-stu-id="92889-205">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="92889-206">Regresní analýzy: Jak interpretovat, spolehlivosti a posoudit ještě lepší-přizpůsobit zobrazení?</span><span class="sxs-lookup"><span data-stu-id="92889-206">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="92889-207">Jak interpretovat spolehlivosti R v regresní analýzy</span><span class="sxs-lookup"><span data-stu-id="92889-207">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="92889-208">Definice spolehlivosti R</span><span class="sxs-lookup"><span data-stu-id="92889-208">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="92889-209">Znamenají kvadratická chyba definice</span><span class="sxs-lookup"><span data-stu-id="92889-209">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="92889-210">Co jsou znamenat kvadratická chyba a kvadratická chyba znamenají kořenové?</span><span class="sxs-lookup"><span data-stu-id="92889-210">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)
